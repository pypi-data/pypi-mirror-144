{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Mar 20:42:17 : plc_smallpower.pkl loaded in 1.89 ms \n",
      "---------------------------------------\n",
      "\n",
      "FINISH LOADING CONFIGURATOR\n",
      "==============================\n",
      "\n",
      "beckhoff  :  1000.0 ms\n",
      "beckhoff  :  100.0 ms\n",
      "FINISH LOADING CONFIGURATOR\n",
      "==============================\n",
      "\n",
      "security check succeeded!\n",
      "\n",
      "initialization of low pass tags done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os,pandas as pd,glob\n",
    "import time,datetime as dt,sys\n",
    "import dorianUtils.comUtils as comUtils\n",
    "import smallPowerDash.smallPower as smallPower\n",
    "start=time.time()\n",
    "dumperSmallPower = smallPower.SmallPower_dumper()\n",
    "beckhoff=dumperSmallPower.devices['beckhoff']\n",
    "baseFolder = '/home/sylfen/data_ext/'\n",
    "FOLDERZIP = baseFolder + 'smallPower_zip_hourly/'\n",
    "FOLDERPARKED_HOURS = baseFolder + '/smallPower_hourly/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumper collect and insert into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "quickTags = dumperSmallPower.dumpInterval['beckhoff'][0.1].argsAction[2]\n",
    "slowTags = dumperSmallPower.dumpInterval['beckhoff'][1].argsAction[2]\n",
    "beckhoffclient = dumperSmallPower.devices['beckhoff']\n",
    "tags=quickTags\n",
    "d=beckhoffclient.collectData(tags,'UTC')\n",
    "df=pd.DataFrame(d).T;df\n",
    "# c=beckhoffclient.insert_intodb(dumperSmallPower.dbParameters,'test_realtimedata',tags,'UTC')\n",
    "# tag=tags[0];value,timestampz=d[tag]\n",
    "# beckhoffclient.generate_sql_insert_tag(tag,value,timestampz,'test_realtimedata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick park on fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 Mar 20:43:27 : database for data <2022-03-29T20:43:27.583407+02:00 read in 153.39 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestampz</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:16.053960+02:00</th>\n",
       "      <td>SEH1.STB_GFC_01_PT_01.HM05</td>\n",
       "      <td>23.8288516998291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:16.053960+02:00</th>\n",
       "      <td>SEH1.STB_STK_03.ET_14.HM05</td>\n",
       "      <td>0.016384124755859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:16.053960+02:00</th>\n",
       "      <td>SEH1.STB_STK_03.ET_15.HM05</td>\n",
       "      <td>0.02195453643798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:16.053960+02:00</th>\n",
       "      <td>SEH1.STB_STK_03.ET_16.HM05</td>\n",
       "      <td>0.004588127136230469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:16.053960+02:00</th>\n",
       "      <td>SEH1.STB_STK_03.ET_17.HM05</td>\n",
       "      <td>0.010158538818359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:27.536995+02:00</th>\n",
       "      <td>SEH1.STK_ALIM_01.ET_HM05</td>\n",
       "      <td>1.5499999523162842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:27.536995+02:00</th>\n",
       "      <td>SEH1.STK_ALIM_01.IT_HM05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:27.536995+02:00</th>\n",
       "      <td>SEH1.STK_ALIM_01.IT_HS00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:27.536995+02:00</th>\n",
       "      <td>SEH1.STK_ALIM_02.ET_HM05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29 20:43:27.536995+02:00</th>\n",
       "      <td>SEH1.STB_STK_04.ET_09.HM05</td>\n",
       "      <td>0.31915760040283203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24516 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         tag  \\\n",
       "timestampz                                                     \n",
       "2022-03-29 20:43:16.053960+02:00  SEH1.STB_GFC_01_PT_01.HM05   \n",
       "2022-03-29 20:43:16.053960+02:00  SEH1.STB_STK_03.ET_14.HM05   \n",
       "2022-03-29 20:43:16.053960+02:00  SEH1.STB_STK_03.ET_15.HM05   \n",
       "2022-03-29 20:43:16.053960+02:00  SEH1.STB_STK_03.ET_16.HM05   \n",
       "2022-03-29 20:43:16.053960+02:00  SEH1.STB_STK_03.ET_17.HM05   \n",
       "...                                                      ...   \n",
       "2022-03-29 20:43:27.536995+02:00    SEH1.STK_ALIM_01.ET_HM05   \n",
       "2022-03-29 20:43:27.536995+02:00    SEH1.STK_ALIM_01.IT_HM05   \n",
       "2022-03-29 20:43:27.536995+02:00    SEH1.STK_ALIM_01.IT_HS00   \n",
       "2022-03-29 20:43:27.536995+02:00    SEH1.STK_ALIM_02.ET_HM05   \n",
       "2022-03-29 20:43:27.536995+02:00  SEH1.STB_STK_04.ET_09.HM05   \n",
       "\n",
       "                                                 value  \n",
       "timestampz                                              \n",
       "2022-03-29 20:43:16.053960+02:00      23.8288516998291  \n",
       "2022-03-29 20:43:16.053960+02:00  0.016384124755859375  \n",
       "2022-03-29 20:43:16.053960+02:00   0.02195453643798828  \n",
       "2022-03-29 20:43:16.053960+02:00  0.004588127136230469  \n",
       "2022-03-29 20:43:16.053960+02:00  0.010158538818359375  \n",
       "...                                                ...  \n",
       "2022-03-29 20:43:27.536995+02:00    1.5499999523162842  \n",
       "2022-03-29 20:43:27.536995+02:00                   0.0  \n",
       "2022-03-29 20:43:27.536995+02:00                   0.0  \n",
       "2022-03-29 20:43:27.536995+02:00                   0.0  \n",
       "2022-03-29 20:43:27.536995+02:00   0.31915760040283203  \n",
       "\n",
       "[24516 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumperSmallPower.park_database(pool_tag=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exportDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = pd.Timestamp.now(tz='CET')\n",
    "t1 = pd.Timestamp('2022-03-27 01:59:59',tz='CET')\n",
    "t0 = pd.Timestamp('2022-03-26 00:00:00',tz='CET')\n",
    "# t0 = t1-pd.Timedelta(hours=t1.hour,minutes=t1.minute,seconds=t1.second)\n",
    "basename='-00-00-3-RealTimeData.csv'\n",
    "dumperSmallPower.exportdb2zip(dumperSmallPower.dbParameters,t0,t1,FOLDERZIP,basename=basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklfile=FOLDERZIP + (t0 + pd.Timedelta(days=1)).strftime(dbparker.streamer.format_dayFolder).split('/')[0]+basename.replace('.csv','.pkl')\n",
    "pklfile=FOLDERZIP + '2022-03-25'+basename.replace('.csv','.pkl')\n",
    "df = pd.read_pickle(pklfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDERPARKED_DAYS=baseFolder+'smallpower_daily_back/'\n",
    "dbparker.streamer.park_DFday(df.reset_index(),FOLDERPARKED_DAYS,pool=False,showtag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# alter parked data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_csv_datetimeTZ(filename):\n",
    "    start   = time.time()\n",
    "    print(\"============================================\")\n",
    "    print('reading of file',filename)\n",
    "    df = pd.read_csv(filename,parse_dates=['timestampz'],names=['tag','value','timestampz'])\n",
    "    print('read in {:.2f} milliseconds'.format((time.time()-start)*1000))\n",
    "    start = time.time()\n",
    "    return df\n",
    "\n",
    "def park_zip_hour_folder(filezip_hour):\n",
    "    '''format of data in the zipFile should be 3 columns tag,value,timestampz with no header.'''\n",
    "    start = time.time()\n",
    "    #### unzip the file\n",
    "    # try:\n",
    "    with ZipFile(filezip_hour, 'r') as zipObj:\n",
    "       zipObj.extractall(FOLDERZIP)\n",
    "    ###read the file\n",
    "    f_csv=filezip_hour.replace('.zip','.csv')\n",
    "    df = read_csv_datetimeTZ(f_csv)\n",
    "    ###remove the csv\n",
    "    os.remove(f_csv)\n",
    "    ###park the file\n",
    "    streamer.park_DF_hour(df,FOLDERPARKED_HOURS,pool=False)\n",
    "    message=filezip_hour+' parked in {:.2f} milliseconds'.format((time.time()-start)*1000)\n",
    "    # except:\n",
    "    #     print()\n",
    "    #     print('************************************')\n",
    "    #     message = filezip_hour+' failed to be parked'\n",
    "    #     print(message)\n",
    "    #     print('************************************')\n",
    "    #     print()\n",
    "    return message\n",
    "\n",
    "def park_hourly2dayly(day,showtag=False):\n",
    "    \"\"\" -day :'ex : 2022-02-15' \"\"\"\n",
    "    listhours=glob.glob(FOLDERPARKED_HOURS+day+'/*')\n",
    "    listhours.sort()\n",
    "    listTags = os.listdir(listhours[0])\n",
    "    folderday=FOLDERPARKED_DAYS +'/'+ day+ '/'\n",
    "    if not os.path.exists(folderday):os.mkdir(folderday)\n",
    "    for tag in listTags:\n",
    "        if showtag:print(tag)\n",
    "        dfs=[pd.read_pickle(hour+'/' + tag) for hour in listhours]\n",
    "        pd.concat(dfs).to_pickle(folderday + tag)\n",
    "    return \n",
    "\n",
    "def applyCorrectFormat(d,cfg,newtz='CET',printag=False,debug=False):\n",
    "    '''\n",
    "    - format as pd.Series with name values and timestamp as index\n",
    "    - remove index duplicates\n",
    "    - convert timezone\n",
    "    - apply correct datatype if bool,float or string\n",
    "    '''\n",
    "    print(d)\n",
    "    tags = os.listdir(d)\n",
    "    for t in tags:\n",
    "        tagpath=d+'/'+t\n",
    "        if printag:print(tagpath)\n",
    "        try:\n",
    "            df=pd.read_pickle(tagpath)\n",
    "        except:\n",
    "            print('pb loading',tagpath)\n",
    "        if df.empty:\n",
    "            print('dataframe empty for ',tagpath)\n",
    "        else:\n",
    "            ##### --- make them format pd.Series with name values and timestamp as index----\n",
    "            if not isinstance(df,pd.core.series.Series):\n",
    "                col_timestamp=[k for k in df.columns if 'timestamp' in k]\n",
    "                df.set_index(col_timestamp)['value'].to_pickle(tagpath)\n",
    "            ##### --- remove index duplicates ----\n",
    "            df = df[~df.index.duplicated(keep='first')]\n",
    "            ##### --- convert timezone----\n",
    "            if isinstance(df.index.dtype,pd.DatetimeTZDtype):\n",
    "                df.index = df.index.tz_convert(newtz)\n",
    "            else:### for cases with changing DST at 31.10 or if it is a string\n",
    "                df.index = [pd.Timestamp(k).astimezone(newtz) for k in df.index]\n",
    "            #####----- apply correct datatype ------\n",
    "            try:\n",
    "                df = df.astype(cfg.dataTypes[cfg.dfplc.loc[t.strip('.pkl'),'DATATYPE']])\n",
    "            except:\n",
    "                print(t,' not in ',cfg.file_plc_xlsm)\n",
    "            df.to_pickle(tagpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderPkl='/home/sylfen/data_ext/smallpower_daily_back/'\n",
    "# folderPkl='/home/sylfen/data_ext/small/'\n",
    "# folderPkl='/home/sylfen/data_ext/smallPower_daily/'\n",
    "lf=os.listdir(FOLDERZIP)\n",
    "lf=os.listdir(folderPkl)\n",
    "lf.sort()\n",
    "lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df  = pd.read_pickle(FOLDERZIP+'/2022-03-25-00-00-x-RealTimeData.pkl')\n",
    "dumperSmallPower.streamer.park_DFday(df.reset_index(),folderPkl,pool=False,showtag=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smallPowerDash.smallPower as smallPower\n",
    "cfg = smallPower.SmallPowerComputer(rebuildConf=False)\n",
    "# listhoursfiles=glob.glob(FOLDERZIP+'/*2022-02-24*')\n",
    "# listhoursfiles\n",
    "# park_zip_hour_folder(listhoursfiles[0])\n",
    "# with Pool(24) as p:p.map(park_zip_hour_folder,listhoursfiles)\n",
    "# park_hourly2dayly('2022-02-24',showtag=True)\n",
    "folderparked_days='/home/sylfen/data_ext/smallpower_daily_back/'\n",
    "folderparked_days='/home/sylfen/data_ext/smallPower_daily/'\n",
    "list_daysfiles=glob.glob(folderparked_days+'/*2022-03-22*')\n",
    "list_daysfiles.sort()\n",
    "for f in list_daysfiles: \n",
    "    applyCorrectFormat(f,cfg,newtz='UTC',printag=True,debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions comUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setInterval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import numpy as np\n",
    "def sleepabit(initValue=0.9):\n",
    "    t0 = dt.datetime.now().astimezone()\n",
    "    print('start time task : ',t0.strftime('%H:%M:%S:%f')[:-4])\n",
    "    value =initValue+np.random.randint(0,20)/100\n",
    "    print('duration task : ',value)\n",
    "    print('')\n",
    "    sleep(value)\n",
    "\n",
    "## initialize a M:S:000 pétante ! #####\n",
    "now =dt.datetime.now().astimezone()\n",
    "time.sleep(1-now.microsecond/1000000)\n",
    "setTest=comUtils.SetInterval(1,sleepabit,0.99)\n",
    "setTest.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## static compression test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s=df.iloc[:,0]\n",
    "# s2=streaming.staticCompressionTag(s,s.std(),method='reduce')\n",
    "\n",
    "s=streaming.generateRampPlateau(nbpts=200)\n",
    "precs=np.logspace(-2,0,6)*5\n",
    "results = streaming.testCompareStaticCompression(s,precs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test reconnection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplc=dumperSmallPower.dfPLC\n",
    "tags = list(dfplc.index[dfplc['FREQUENCE_ECHANTILLONNAGE']==0.1])\n",
    "quickNodes = {t:dumperSmallPower.nodesDict[t] for t in tags}\n",
    "for k in range(2):\n",
    "        # d=dumperSmallPower.collectData(quickNodes)\n",
    "        c=dumperSmallPower.insert_intodb(quickNodes)\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check acquisition times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2pdf = lambda d:pd.DataFrame.from_dict(d,orient='index').squeeze().sort_values()\n",
    "s_collect = dict2pdf(dumperSmallPower.collectingTimes)\n",
    "s_insert  = dict2pdf(dumperSmallPower.insertingTimes)\n",
    "\n",
    "p = 1. * np.arange(len(s_collect))\n",
    "## first x axis :\n",
    "tr1 = go.Scatter(x=p,y=df,name='collectingTime',col=1,row=1)\n",
    "## second axis\n",
    "tr2 = go.Scatter(x=p,y=df,name='collectingTime',col=1,row=2)\n",
    "title1='cumulative probability density '\n",
    "title2='histogramm computing times '\n",
    "# fig.update_layout(titles=)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
