{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90dda43",
   "metadata": {},
   "source": [
    "# Notebook script for generation of training dataset (supports single and two phase material)\n",
    "\n",
    "## For case of more than two phase, the code below can be adapted\n",
    "\n",
    "## Different steps of data generation is outlined in this notebook (LaueToolsNN GUI does the same thing)\n",
    "\n",
    "### Define material of interest\n",
    "### Generate class hkl data for Neural Network model (these are the output neurons)\n",
    "### Clean up generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879b9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules used for this Notebook\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "## if LaueToolsNN is properly installed\n",
    "try:\n",
    "    from lauetoolsnn.utils_lauenn import generate_classHKL, generate_dataset, \\\n",
    "                                SGLattice, array_generator, rmv_freq_class, \\\n",
    "                                array_generator_verify, vali_array, get_material_detail\n",
    "    from lauetoolsnn.lauetools import dict_LaueTools as dictLT\n",
    "    from lauetoolsnn.lauetools import CrystalParameters as CP\n",
    "except:\n",
    "    # else import from a path where LaueToolsNN files are\n",
    "    import sys\n",
    "    sys.path.append(r\"C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\")\n",
    "    from utils_lauenn import generate_classHKL, generate_dataset, \\\n",
    "                        SGLattice, array_generator, rmv_freq_class, \\\n",
    "                        array_generator_verify, vali_array, get_material_detail\n",
    "    sys.path.append(r\"C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\lauetools\")\n",
    "    import dict_LaueTools as dictLT\n",
    "    import CrystalParameters as CP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad431ffc",
   "metadata": {},
   "source": [
    "## step 1: define material and other parameters for simulating Laue patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3284dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "## User Input dictionary with parameters\n",
    "## In case of only one phase/material, keep same value for material_ and material1_ key\n",
    "# =============================================================================\n",
    "input_params = {\n",
    "                \"material_\": \"Cu\",             ## same key as used in dict_LaueTools\n",
    "                \"material1_\": \"Cu\",            ## same key as used in dict_LaueTools\n",
    "                \"prefix\" : \"\",                 ## prefix for the folder to be created for training dataset\n",
    "                \"symmetry\": \"cubic\",           ## crystal symmetry of material_\n",
    "                \"symmetry1\": \"cubic\",          ## crystal symmetry of material1_\n",
    "                \"SG\": 225,                     ## Space group of material_ (None if not known)\n",
    "                \"SG1\": 225,                    ## Space group of material1_ (None if not known)\n",
    "                \"hkl_max_identify\" : 5,        ## Maximum hkl index to classify in a Laue pattern\n",
    "                \"maximum_angle_to_search\" : 90,## Angle of radial distribution to reconstruct the histogram (in deg)\n",
    "                \"step_for_binning\" : 0.1,      ## bin widht of angular radial distribution in degree\n",
    "                \"nb_grains_per_lp\" : 5,        ## max grains to be generated in a Laue Image\n",
    "                \"grains_nb_simulate\" : 100,    ## Number of orientations to generate (takes advantage of crystal symmetry)\n",
    "                ## Detector parameters (roughly) of the Experimental setup\n",
    "                ## Sample-detector distance, X center, Y center, two detector angles\n",
    "                \"detectorparameters\" :  [79.553,979.32,932.31,0.37,0.447], \n",
    "                \"pixelsize\" : 0.0734,          ## Detector pixel size\n",
    "                \"dim1\":2018,                   ## Dimensions of detector in pixels\n",
    "                \"dim2\":2016,\n",
    "                \"emin\" : 5,                    ## Minimum and maximum energy to use for simulating Laue Patterns\n",
    "                \"emax\" : 22,\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3f3b0",
   "metadata": {},
   "source": [
    "## Step 2: Get material parameters \n",
    "### Generates a folder with material name and gets material unit cell parameters and symmetry object from the get_material_detail function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f45b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save directory is : C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\example_notebook_scripts//Cu\n"
     ]
    }
   ],
   "source": [
    "material_= input_params[\"material_\"]\n",
    "material1_= input_params[\"material1_\"]\n",
    "n = input_params[\"hkl_max_identify\"]\n",
    "maximum_angle_to_search = input_params[\"maximum_angle_to_search\"]\n",
    "step_for_binning = input_params[\"step_for_binning\"]\n",
    "nb_grains_per_lp = input_params[\"nb_grains_per_lp\"]\n",
    "grains_nb_simulate = input_params[\"grains_nb_simulate\"]\n",
    "detectorparameters = input_params[\"detectorparameters\"]\n",
    "pixelsize = input_params[\"pixelsize\"]\n",
    "emax = input_params[\"emax\"]\n",
    "emin = input_params[\"emin\"]\n",
    "symm_ = input_params[\"symmetry\"]\n",
    "symm1_ = input_params[\"symmetry1\"]\n",
    "SG = input_params[\"SG\"]\n",
    "SG1 = input_params[\"SG1\"]\n",
    "\n",
    "if material_ != material1_:\n",
    "    save_directory = os.getcwd()+\"//\"+material_+\"_\"+material1_+input_params[\"prefix\"]\n",
    "else:\n",
    "    save_directory = os.getcwd()+\"//\"+material_+input_params[\"prefix\"]\n",
    "print(\"save directory is : \"+save_directory)\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "## get unit cell parameters and other details required for simulating Laue patterns\n",
    "rules, symmetry, lattice_material, \\\n",
    "    crystal, SG, rules1, symmetry1,\\\n",
    "    lattice_material1, crystal1, SG1 = get_material_detail(material_, SG, symm_,\n",
    "                                                           material1_, SG1, symm1_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac29a6",
   "metadata": {},
   "source": [
    "## Step 3: Generate Neural network output classes (Laue spot hkls) using the generate_classHKL function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b059eb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating HKL objects\n",
      "Removing harmonics and building equivalent HKL objects\n",
      "Finalizing the HKL objects\n",
      "Saved class HKL data in : C:\\Users\\purushot\\Desktop\\github_version_simple\\lauetoolsnn\\example_notebook_scripts//Cu//classhkl_data_Cu.pickle\n"
     ]
    }
   ],
   "source": [
    "## procedure for generation of GROUND TRUTH classes\n",
    "# general_diff_cond = True will eliminate the hkl index that does not satisfy the general reflection conditions\n",
    "generate_classHKL(n, rules, lattice_material, symmetry, material_, crystal=crystal, SG=SG, general_diff_cond=False,\n",
    "          save_directory=save_directory, write_to_console=print, ang_maxx = maximum_angle_to_search, \n",
    "          step = step_for_binning)\n",
    "\n",
    "if material_ != material1_:\n",
    "    generate_classHKL(n, rules1, lattice_material1, symmetry1, material1_, crystal=crystal1, SG=SG1, general_diff_cond=False,\n",
    "              save_directory=save_directory, write_to_console=print, ang_maxx = maximum_angle_to_search, \n",
    "              step = step_for_binning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a0365",
   "metadata": {},
   "source": [
    "## Step 4: Generate Training and Testing dataset only for the output classes (Laue spot hkls) calculated in the Step 3\n",
    "### Uses multiprocessing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "665a651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying if two different HKL class have same angular distribution (can be very time consuming depending on the symmetry)\n",
      "Great! No two HKL class have same angular distribution\n",
      "Generating training_data and saving them\n",
      "Verifying if two different HKL class have same angular distribution (can be very time consuming depending on the symmetry)\n",
      "Great! No two HKL class have same angular distribution\n",
      "Generating testing_data and saving them\n",
      "First material index length: 40\n",
      "Class ID and frequency; check for data imbalance and select                             appropriate LOSS function for training the model\n",
      "[(28, 5595), (9, 4272), (7, 3676), (11, 3393), (3, 3342), (4, 3224), (23, 3033), (5, 2794), (6, 2591), (30, 2583), (15, 2560), (36, 2307), (8, 2245), (38, 2036), (1, 1822), (10, 1756), (13, 1655), (17, 1559), (14, 1554), (2, 1204), (12, 1173), (18, 1063), (16, 898), (0, 886), (25, 886), (22, 723), (24, 526), (26, 264), (20, 260), (27, 213), (19, 182), (29, 8)]\n",
      "HKL : [1. 3. 5.]; occurance : 5595: NN_weights : 1\n",
      "HKL : [1. 2. 3.]; occurance : 4272: NN_weights : 1\n",
      "HKL : [1. 1. 3.]; occurance : 3676: NN_weights : 1\n",
      "HKL : [1. 3. 3.]; occurance : 3393: NN_weights : 1\n",
      "HKL : [0. 1. 2.]; occurance : 3342: NN_weights : 1\n",
      "HKL : [1. 1. 2.]; occurance : 3224: NN_weights : 1\n",
      "HKL : [1. 1. 5.]; occurance : 3033: NN_weights : 1\n",
      "HKL : [1. 2. 2.]; occurance : 2794: NN_weights : 2\n",
      "HKL : [0. 1. 3.]; occurance : 2591: NN_weights : 2\n",
      "HKL : [3. 3. 5.]; occurance : 2583: NN_weights : 2\n",
      "HKL : [1. 2. 4.]; occurance : 2560: NN_weights : 2\n",
      "HKL : [1. 5. 5.]; occurance : 2307: NN_weights : 2\n",
      "HKL : [0. 2. 3.]; occurance : 2245: NN_weights : 2\n",
      "HKL : [3. 5. 5.]; occurance : 2036: NN_weights : 2\n",
      "HKL : [0. 1. 1.]; occurance : 1822: NN_weights : 3\n",
      "HKL : [2. 2. 3.]; occurance : 1756: NN_weights : 3\n",
      "HKL : [0. 1. 4.]; occurance : 1655: NN_weights : 3\n",
      "HKL : [1. 3. 4.]; occurance : 1559: NN_weights : 3\n",
      "HKL : [1. 1. 4.]; occurance : 1554: NN_weights : 3\n",
      "HKL : [1. 1. 1.]; occurance : 1204: NN_weights : 4\n",
      "HKL : [2. 3. 3.]; occurance : 1173: NN_weights : 4\n",
      "HKL : [2. 3. 4.]; occurance : 1063: NN_weights : 5\n",
      "HKL : [0. 3. 4.]; occurance : 898: NN_weights : 6\n",
      "HKL : [0. 0. 1.]; occurance : 886: NN_weights : 6\n",
      "HKL : [1. 2. 5.]; occurance : 886: NN_weights : 6\n",
      "HKL : [0. 1. 5.]; occurance : 723: NN_weights : 7\n",
      "HKL : [0. 2. 5.]; occurance : 526: NN_weights : 10\n",
      "HKL : [2. 2. 5.]; occurance : 264: NN_weights : 21\n",
      "HKL : [1. 4. 4.]; occurance : 260: NN_weights : 21\n",
      "HKL : [0. 3. 5.]; occurance : 213: NN_weights : 26\n",
      "HKL : [3. 3. 4.]; occurance : 182: NN_weights : 30\n",
      "9 classes removed from the classHKL object [removal frequency: 100] (before:40, now:31)\n",
      "9 classes removed from the classHKL object [removal frequency: 100] (before:40, now:31)\n",
      "Saved class weights data\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':     #enclosing required because of multiprocessing\n",
    "    ############ GENERATING TRAINING DATA ##############\n",
    "    # data_realism =True ; will introduce noise and partial Laue patterns in the training dataset\n",
    "    # modelp can have either \"random\" for random orientation generation or \"uniform\" for uniform orientation generation\n",
    "    # include_scm (if True; misorientation_angle parameter need to be defined): this parameter introduces misoriented crystal of specific angle along a crystal axis in the training dataset\n",
    "    generate_dataset(material_=material_, material1_=material1_, ang_maxx=maximum_angle_to_search,\n",
    "                         step=step_for_binning, mode=0, \n",
    "                         nb_grains=nb_grains_per_lp, nb_grains1=nb_grains_per_lp, \n",
    "                         grains_nb_simulate=grains_nb_simulate, data_realism = True, \n",
    "                         detectorparameters=detectorparameters, pixelsize=pixelsize, type_=\"training_data\",\n",
    "                         var0 = 1, dim1=input_params[\"dim1\"], dim2=input_params[\"dim2\"], \n",
    "                         removeharmonics=1, save_directory=save_directory,\n",
    "                        write_to_console=print, emin=emin, emax=emax, modelp = \"random\",\n",
    "                        misorientation_angle = 1, general_diff_rules = False, \n",
    "                        crystal = crystal, crystal1 = crystal1, include_scm=False,)\n",
    "    \n",
    "    ############ GENERATING TESTING DATA ##############\n",
    "    factor = 5 # validation split for the training dataset  --> corresponds to 20% of total training dataset\n",
    "    generate_dataset(material_=material_, material1_=material1_, ang_maxx=maximum_angle_to_search,\n",
    "                         step=step_for_binning, mode=0, \n",
    "                         nb_grains=nb_grains_per_lp, nb_grains1=nb_grains_per_lp, \n",
    "                         grains_nb_simulate=grains_nb_simulate//factor, data_realism = True, \n",
    "                         detectorparameters=detectorparameters, pixelsize=pixelsize, type_=\"testing_data\",\n",
    "                         var0 = 1, dim1=input_params[\"dim1\"], dim2=input_params[\"dim2\"], \n",
    "                         removeharmonics=1, save_directory=save_directory,\n",
    "                        write_to_console=print, emin=emin, emax=emax, modelp = \"random\",\n",
    "                        misorientation_angle = 1, general_diff_rules = False, \n",
    "                        crystal = crystal, crystal1 = crystal1, include_scm=False,)\n",
    "    \n",
    "    ## Updating the ClassHKL list by removing the non-common HKL or less frequent HKL from the list\n",
    "    ## The non-common HKL can occur as a result of the detector position and energy used\n",
    "    # freq_rmv: remove output hkl if the training dataset has less tha 100 occurances of the considered hkl (freq_rmv1 for second phase)\n",
    "    # Weights (penalty during training) are also calculated based on the occurance\n",
    "    rmv_freq_class(freq_rmv = 100, freq_rmv1 = 100,\n",
    "                        save_directory=save_directory, material_=material_, \n",
    "                        material1_=material1_, write_to_console=print)\n",
    "    \n",
    "    ## End of data generation for Neural network training: all files are saved in the same folder to be later used for training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bdb903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
