{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do I wrap my own recordings?\n",
    "\n",
    "If you have your own recordings on disk and want to make use of Tonic for quick dataloading and applying transformations, then you can wrap them in a custom class.\n",
    "The easiest option is to make use of a torchvision [DatasetFolder](https://pytorch.org/vision/main/datasets.html#torchvision.datasets.DatasetFolder) class. If that doesn't apply in your case, you can write your own class, where you provide a minimum set of methods ``__init__``, ``__getitem__`` and ``__len__`` and you are good to go. Here is a template class that reads event recordings from a local hdf5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tonic import Dataset\n",
    "\n",
    "class MyRecordings(Dataset):\n",
    "    sensor_size = (700,) # the sensor size of the event camera or the number of channels of the silicon cochlear that was used\n",
    "    ordering = \"txp\" # the order in which your event channels are provided in your recordings\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train=True,\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "    ):\n",
    "        super(MyRecordings, self).__init__(\n",
    "            transform=transform, target_transform=target_transform\n",
    "        )\n",
    "        self.train = train\n",
    "\n",
    "        # replace the strings with your training/testing file locations or pass as an argument\n",
    "        if train:\n",
    "            self.filename = \"/opt/data1/data/shd_train.h5\"\n",
    "        else:\n",
    "            self.filename = \"/opt/data1/data/shd_test.h5\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = h5py.File(self.filename, \"r\")\n",
    "        # adding artificial polarity of 1\n",
    "        events = np.vstack((file[\"spikes/times\"][index], file[\"spikes/units\"][index], np.ones(file[\"spikes/times\"][index].shape[0]))).T\n",
    "        # convert to microseconds\n",
    "        events[:,0] *= 1e6\n",
    "        target = file[\"labels\"][index].astype(int)\n",
    "        if self.transform is not None:\n",
    "            events = self.transform(events, self.sensor_size, self.ordering)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return events, target\n",
    "\n",
    "    def __len__(self):\n",
    "        file = h5py.File(self.filename, \"r\")\n",
    "        return len(file[\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the format of your recording files, your implementation might look a bit different. Oftentimes you will have a separate file for each recording. Or you might want to also load some image or IMU data. You can have a look at already existing datasets for some inspiration. :class:`DVSGesture` loads from multiple numpy files, :class:`DAVISDATA` or :class:`VPR` load events and other data from rosbag files, :class:`NCARS` loads eventstream files and :class:`ASLDVS` reads from matlab files.\n",
    "\n",
    "Afterwards you can call certain samples from the dataset or use a DataLoader wrapper, which will make use of ``__getitem__`` and ``__len__`` functions internally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyRecordings(train=True)\n",
    "events, target = dataset[100]\n",
    "\n",
    "import torch\n",
    "dataloader = torch.utils.data.DataLoader(dataset, shuffle=True)\n",
    "events, target = next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5931241afb711235dda64ee4fe99a453ecee36036d1d9ee62f788faeb386adff"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
